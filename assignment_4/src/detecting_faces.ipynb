{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.13.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ucloud/.local/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in /home/ucloud/.local/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.3.0 (from torch)\n",
      "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ucloud/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.4)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.13.4-py3-none-any.whl (11 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "Successfully installed filelock-3.13.4 fsspec-2024.3.1 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sympy-1.12 torch-2.3.0 triton-2.3.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement PIL (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for PIL\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting facenet-pytorch\n",
      "  Downloading facenet_pytorch-2.5.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy (from facenet-pytorch)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ucloud/.local/lib/python3.10/site-packages (from facenet-pytorch) (2.31.0)\n",
      "Collecting torchvision (from facenet-pytorch)\n",
      "  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting pillow (from facenet-pytorch)\n",
      "  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ucloud/.local/lib/python3.10/site-packages (from requests->facenet-pytorch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ucloud/.local/lib/python3.10/site-packages (from requests->facenet-pytorch) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ucloud/.local/lib/python3.10/site-packages (from requests->facenet-pytorch) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ucloud/.local/lib/python3.10/site-packages (from requests->facenet-pytorch) (2023.11.17)\n",
      "Requirement already satisfied: torch==2.3.0 in /home/ucloud/.local/lib/python3.10/site-packages (from torchvision->facenet-pytorch) (2.3.0)\n",
      "Requirement already satisfied: filelock in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/ucloud/.local/lib/python3.10/site-packages (from torch==2.3.0->torchvision->facenet-pytorch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ucloud/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->torchvision->facenet-pytorch) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ucloud/.local/lib/python3.10/site-packages (from jinja2->torch==2.3.0->torchvision->facenet-pytorch) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ucloud/.local/lib/python3.10/site-packages (from sympy->torch==2.3.0->torchvision->facenet-pytorch) (1.3.0)\n",
      "Downloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pillow, numpy, torchvision, facenet-pytorch\n",
      "Successfully installed facenet-pytorch-2.5.3 numpy-1.26.4 pillow-10.3.0 torchvision-0.18.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch \n",
    "%pip install PIL\n",
    "%pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089f430d38e94c73982af6b2cc29bbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/111M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize MTCNN for face detection\n",
    "mtcnn = MTCNN(keep_all=True)\n",
    "\n",
    "# Load pre-trained FaceNet model\n",
    "resnet = InceptionResnetV1(pretrained='casia-webface').eval()\n",
    "\n",
    "# Load an image containing faces\n",
    "img = Image.open('../../../../../cds-vis-data/newspapers/GDL/GDL-1798-02-05-a-p0001.jpg') #0 faces\n",
    "img_2 = Image.open('../../../../../cds-vis-data/newspapers/GDL/GDL-1987-08-21-a-p0012.jpg') #1 face \n",
    "img_3 =  Image.open('../../../../../cds-vis-data/newspapers/GDL/GDL-1997-08-09-a-p0021.jpg') #4 faces\n",
    "\n",
    "\n",
    "# Detect faces in the image\n",
    "boxes, _ = mtcnn.detect(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/work/IdaHeleneDencker#2808/CDS_visual/CDS_vis24/assignment_4/src/detecting_faces.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://app-5040556-0.cloud.sdu.dk/work/IdaHeleneDencker%232808/CDS_visual/CDS_vis24/assignment_4/src/detecting_faces.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#img_2 contains 1 face and returns 1 list with 1 of 4 numbers: [[594.2079467773438 1372.92529296875 678.6680908203125 1482.1539306640625]]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://app-5040556-0.cloud.sdu.dk/work/IdaHeleneDencker%232808/CDS_visual/CDS_vis24/assignment_4/src/detecting_faces.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#img_3 contains 4 faces and return 1 list with 4 list \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://app-5040556-0.cloud.sdu.dk/work/IdaHeleneDencker%232808/CDS_visual/CDS_vis24/assignment_4/src/detecting_faces.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://app-5040556-0.cloud.sdu.dk/work/IdaHeleneDencker%232808/CDS_visual/CDS_vis24/assignment_4/src/detecting_faces.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#to get the number of faces access the first element in boxes\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://app-5040556-0.cloud.sdu.dk/work/IdaHeleneDencker%232808/CDS_visual/CDS_vis24/assignment_4/src/detecting_faces.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m boxes\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "#img_2 contains 1 face and returns 1 list with 1 of 4 numbers: [[594.2079467773438 1372.92529296875 678.6680908203125 1482.1539306640625]]\n",
    "#img_3 contains 4 faces and return 1 list with 4 list \n",
    "\n",
    "#to get the number of faces access the first element in boxes\n",
    "boxes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 1:\n",
    "\n",
    "\n",
    "# Initialize MTCNN for face detection:\n",
    "#mtcnn = MTCNN(keep_all=True)\n",
    "\n",
    "# Load pre-trained FaceNet model:\n",
    "#resnet = InceptionResnetV1(pretrained='casia-webface').eval()\n",
    "\n",
    "\n",
    "# Initialize dictionaries:\n",
    "#faces_rawcount_per_decade = {}  # Dictionary to store raw counts of images with faces per decade for each newspaper\n",
    "#perc_pages_with_faces_per_decade = {}  # Dictionary to store percentage of pages with faces per decade for each newspaper\n",
    "\n",
    "\n",
    "#define folderpath:\n",
    "#folderpath = ....\n",
    "\n",
    "#create a csv for each of the 3 newspapers: \n",
    "#loop through each subfolder (1 subfolder=1 newspaper) in folderpath\n",
    "\n",
    "    #extract name of newspaper:\n",
    "    #newpaper_name = extract name of the subfolder\n",
    "\n",
    "    #loop thoguh each file in subfolder:\n",
    "\n",
    "        ##to get decade: \n",
    "\n",
    "        # load in image:\n",
    "        #img= Image.open(path_to_image)\n",
    "\n",
    "        # get filename:\n",
    "        #filename = what comes after the last '/' in path_to_image\n",
    "\n",
    "        #between the first '-' and second '-' in filename extract 3 first numbers:\n",
    "        #3_numbers = \n",
    "\n",
    "        #add a 0 to the end: \n",
    "        #4_numbers= 3_numbers + \"0\"\n",
    "\n",
    "        #add every unique instances to faces_rawcount_per_decade dictiory: \n",
    "        #if 4_numbers is not allready in faces_rawcount_per_decade, add it to the list\n",
    "            #else skip\n",
    "        \n",
    "        #for each element in decades dictiory, count the rawcount of faces:\n",
    "\n",
    "\n",
    "            #detect faces \n",
    "            #boxes, _ = mtcnn.detect(img)\n",
    "        \n",
    "\n",
    "            #if shape of boxes == Nonce\n",
    "                #add 0 to faces_on_page\n",
    "\n",
    "                #else\n",
    "                    #number_to_add = boxes.shape[0]\n",
    "                    #add number_to_add to faces_on_page_count\n",
    "            \n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/ucloud/.local/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ucloud/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.51.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.5/159.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/ucloud/.local/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ucloud/.local/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/ucloud/.local/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ucloud/.local/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (305 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.51.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.51.0 kiwisolver-1.4.5 matplotlib-3.8.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs took about 7 min, for 3*8 files (machine 4)\n",
    "\n",
    "#new, WORKING BUT NOT QUITE RIGHT \n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "# Initialize MTCNN for face detection:\n",
    "mtcnn = MTCNN()\n",
    "\n",
    "# Define folder path\n",
    "folderpath = \"../newspapers_2/\"\n",
    "\n",
    "# Initialize dictionaries to store results:\n",
    "faces_rawcount_per_decade = {}  # Store raw counts of images with faces per decade for each newspaper\n",
    "perc_pages_with_faces_per_decade = {}  # Store percentage of pages with faces per decade for each newspaper\n",
    "\n",
    "# Function to extract decade from filename:\n",
    "def extract_decade(filename):\n",
    "    parts = filename.split(\"-\") #plits the filename into parts seperated by -\n",
    "    year = int(parts[1])  # Extract year from filename, be taking the second part of the filename and making if from string to integer\n",
    "    decade = (year // 10) * 10  #year is devided by 10 and the integer division // gets rid of any decimals, it is then multiplied by 10 to get the 0 as last number\n",
    "    return decade\n",
    "\n",
    "# Iterate through each subfolder (newspaper) in folderpath:\n",
    "for newspaper_folder in os.listdir(folderpath):\n",
    "\n",
    "    # Construct the path to the newspaper we are looping through \n",
    "    full_path = os.path.join(folderpath, newspaper_folder)\n",
    "\n",
    "    # Check if the path full_path exist as a directory, and will procede if it is \n",
    "    if os.path.isdir(full_path):\n",
    "\n",
    "        # Extract the name of the newspaper from the folder path\n",
    "        newspaper_name = newspaper_folder.upper() #obs all are upper, so could delete that\n",
    "\n",
    "        # Initialize dictionaries for the current newspaper\n",
    "        faces_rawcount_per_decade[newspaper_name] = {}\n",
    "        perc_pages_with_faces_per_decade[newspaper_name] = {}\n",
    "        \n",
    "        # Iterate through each file in the subfolder (newspaper):\n",
    "        for filename in os.listdir(full_path):\n",
    "\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(full_path, filename)\n",
    "\n",
    "            # Check if the current item is a file and ends with \".jpg\", because there is a readme file in the newspaper folder\n",
    "            if os.path.isfile(file_path) and filename.endswith(\".jpg\"):\n",
    "\n",
    "                # Proceed with processing the image file\n",
    "                # Open the image file\n",
    "                img = Image.open(file_path)\n",
    "\n",
    "                # Extract the decade from the filename\n",
    "                decade = extract_decade(filename)\n",
    "                \n",
    "                # Detect faces in the image:\n",
    "                boxes, _ = mtcnn.detect(img)\n",
    "\n",
    "\n",
    "                # Count faces per decade:\n",
    "                # Check if any face is detected\n",
    "                if boxes is not None:\n",
    "                    num_faces = boxes.shape[0]  # Count the number of detected faces\n",
    "                else:\n",
    "                    num_faces = 0  # No faces detected\n",
    "\n",
    "                #make a varible for whether the the file contains at least 1 image (for calculating %)\n",
    "                #if num_faces = 0\n",
    "                    #assign is_face_present = 0\n",
    "                #if num_faces != 0\n",
    "                    #assign is_face_present = 1\n",
    "                \n",
    "                # Update the count of faces for the current decade, based on wheter the decade is allready there\n",
    "                if decade not in faces_rawcount_per_decade[newspaper_name]:\n",
    "                    faces_rawcount_per_decade[newspaper_name][decade] = num_faces #if not there, add the number as the first one\n",
    "                else:\n",
    "                    faces_rawcount_per_decade[newspaper_name][decade] += num_faces #if there, add the number to what is allready there\n",
    "\n",
    "\n",
    "\n",
    "        # now for calculating the percentage of pages with faces per decade:\n",
    "        # Calculate the total number of pages in the current newspaper\n",
    "        total_pages = len([filename for filename in os.listdir(full_path) if filename.endswith(\".jpg\")]) \n",
    "        \n",
    "        # Iterate through each decade and calculate the percentage of pages with faces:\n",
    "\n",
    "        #iterates over each key-value pair in the faces_rawcount_per_decade[newspaper_name] dictionary.\n",
    "        for decade, faces_count in faces_rawcount_per_decade[newspaper_name].items():\n",
    "            \n",
    "            # Calculate the percentage\n",
    "            percentage = (faces_count / total_pages) * 100 \n",
    "            # Store the percentage in the dictionary\n",
    "            perc_pages_with_faces_per_decade[newspaper_name][decade] = percentage\n",
    "\n",
    "\n",
    "    #save results to df\n",
    "    for newspaper_name, data in faces_rawcount_per_decade.items():\n",
    "        df = pd.DataFrame.from_dict(data, orient='index', columns=['Faces_Count'])\n",
    "        df.to_csv(f'../out/{newspaper_name}_faces_per_decade.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save results into CSV files:\n",
    "#for newspaper_name, data in faces_rawcount_per_decade.items():\n",
    "    #df = pd.DataFrame.from_dict(data, orient='index', columns=['Faces_Count'])\n",
    "    #df.to_csv(f'../out/{newspaper_name}_faces_per_decade.csv')\n",
    "\n",
    "#for newspaper_name, data in perc_pages_with_faces_per_decade.items():\n",
    "    #df = pd.DataFrame.from_dict(data, orient='index', columns=['Percentage'])\n",
    "    #df.to_csv(f'..out/{newspaper_name}_percentage_per_decade.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../newspapers_2/GDL/GDL-1798-02-05-a-p0001.jpg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IMP': {2010: 137.5, 1880: 0.0},\n",
       " 'JDG': {1990: 25.0, 1820: 0.0},\n",
       " 'GDL': {1990: 12.5, 1790: 0.0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_pages_with_faces_per_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for newspaper_name, data in faces_rawcount_per_decade.items():\n",
    "        df = pd.DataFrame.from_dict(data, \n",
    "        orient='index', columns=['Faces_Count'])\n",
    "\n",
    "        df.to_csv(f'../out/{newspaper_name}_faces_per_decade.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IMP': {2010: 11, 1880: 0},\n",
       " 'JDG': {1990: 2, 1820: 0},\n",
       " 'GDL': {1990: 1, 1790: 0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces_rawcount_per_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/work/IdaHeleneDencker#2808/CDS_visual/CDS_vis24/assignment_4/src/detecting_faces.ipynb Cell 13\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell://app-5040556-0.cloud.sdu.dk/work/IdaHeleneDencker%232808/CDS_visual/CDS_vis24/assignment_4/src/detecting_faces.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39m# Iterate through each decade and calculate the percentage of pages with faces:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://app-5040556-0.cloud.sdu.dk/work/IdaHeleneDencker%232808/CDS_visual/CDS_vis24/assignment_4/src/detecting_faces.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=88'>89</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://app-5040556-0.cloud.sdu.dk/work/IdaHeleneDencker%232808/CDS_visual/CDS_vis24/assignment_4/src/detecting_faces.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=89'>90</a>\u001b[0m \u001b[39m#iterates over each key-value pair in the faces_rawcount_per_decade[newspaper_name] dictionary.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://app-5040556-0.cloud.sdu.dk/work/IdaHeleneDencker%232808/CDS_visual/CDS_vis24/assignment_4/src/detecting_faces.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=90'>91</a>\u001b[0m \u001b[39mfor\u001b[39;00m decade, is_face_present \u001b[39min\u001b[39;00m faces_rawcount_per_decade[newspaper_name]\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     <a href='vscode-notebook-cell://app-5040556-0.cloud.sdu.dk/work/IdaHeleneDencker%232808/CDS_visual/CDS_vis24/assignment_4/src/detecting_faces.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=91'>92</a>\u001b[0m     \n\u001b[1;32m     <a href='vscode-notebook-cell://app-5040556-0.cloud.sdu.dk/work/IdaHeleneDencker%232808/CDS_visual/CDS_vis24/assignment_4/src/detecting_faces.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=92'>93</a>\u001b[0m     \u001b[39m# Calculate the percentage\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://app-5040556-0.cloud.sdu.dk/work/IdaHeleneDencker%232808/CDS_visual/CDS_vis24/assignment_4/src/detecting_faces.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=93'>94</a>\u001b[0m     percentage \u001b[39m=\u001b[39m (\u001b[39msum\u001b[39;49m(is_face_present) \u001b[39m/\u001b[39m total_pages) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m \n\u001b[1;32m     <a href='vscode-notebook-cell://app-5040556-0.cloud.sdu.dk/work/IdaHeleneDencker%232808/CDS_visual/CDS_vis24/assignment_4/src/detecting_faces.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=94'>95</a>\u001b[0m     \u001b[39m# Store the percentage in the dictionary\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://app-5040556-0.cloud.sdu.dk/work/IdaHeleneDencker%232808/CDS_visual/CDS_vis24/assignment_4/src/detecting_faces.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=95'>96</a>\u001b[0m     perc_pages_with_faces_per_decade[newspaper_name][decade] \u001b[39m=\u001b[39m percentage\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "#NEW, FIXING PERCENTAGE\n",
    "\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "# Initialize MTCNN for face detection:\n",
    "mtcnn = MTCNN()\n",
    "\n",
    "# Define folder path\n",
    "folderpath = \"../newspapers_2/\"\n",
    "\n",
    "# Initialize dictionaries to store results:\n",
    "faces_rawcount_per_decade = {}  # Store raw counts of images with faces per decade for each newspaper\n",
    "perc_pages_with_faces_per_decade = {}  # Store percentage of pages with faces per decade for each newspaper\n",
    "\n",
    "# Function to extract decade from filename:\n",
    "def extract_decade(filename):\n",
    "    parts = filename.split(\"-\") #plits the filename into parts seperated by -\n",
    "    year = int(parts[1])  # Extract year from filename, be taking the second part of the filename and making if from string to integer\n",
    "    decade = (year // 10) * 10  #year is devided by 10 and the integer division // gets rid of any decimals, it is then multiplied by 10 to get the 0 as last number\n",
    "    return decade\n",
    "\n",
    "# Iterate through each subfolder (newspaper) in folderpath:\n",
    "for newspaper_folder in os.listdir(folderpath):\n",
    "\n",
    "    # Construct the path to the newspaper we are looping through \n",
    "    full_path = os.path.join(folderpath, newspaper_folder)\n",
    "\n",
    "    # Check if the path full_path exist as a directory, and will procede if it is \n",
    "    if os.path.isdir(full_path):\n",
    "\n",
    "        # Extract the name of the newspaper from the folder path\n",
    "        newspaper_name = newspaper_folder.upper() #obs all are upper, so could delete that\n",
    "\n",
    "        # Initialize dictionaries for the current newspaper\n",
    "        faces_rawcount_per_decade[newspaper_name] = {}\n",
    "        perc_pages_with_faces_per_decade[newspaper_name] = {}\n",
    "        \n",
    "        # Initialize counter for pages with faces for the current decade\n",
    "        pages_with_faces = 0\n",
    "\n",
    "        # Iterate through each file in the subfolder (newspaper):\n",
    "        for filename in os.listdir(full_path):\n",
    "\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(full_path, filename)\n",
    "\n",
    "            # Check if the current item is a file and ends with \".jpg\", because there is a readme file in the newspaper folder\n",
    "            if os.path.isfile(file_path) and filename.endswith(\".jpg\"):\n",
    "\n",
    "                # Proceed with processing the image file\n",
    "                # Open the image file\n",
    "                img = Image.open(file_path)\n",
    "\n",
    "                # Extract the decade from the filename\n",
    "                decade = extract_decade(filename)\n",
    "                \n",
    "                # Detect faces in the image:\n",
    "                boxes, _ = mtcnn.detect(img)\n",
    "\n",
    "\n",
    "                # Count faces per decade:\n",
    "                # Check if any face is detected\n",
    "                if boxes is not None:\n",
    "                    num_faces = boxes.shape[0]  # Count the number of detected faces\n",
    "                else:\n",
    "                    num_faces = 0  # No faces detected\n",
    "\n",
    "                #make a varible for whether the the file contains at least 1 image (for calculating % later)\n",
    "                if boxes is not None and len(num_faces) > 0:\n",
    "                # Increment the counter if at least one face is detected on this page\n",
    "                pages_with_faces += 1\n",
    "                \n",
    "                # Update the count of faces for the current decade, based on wheter the decade is allready there\n",
    "                if decade not in faces_rawcount_per_decade[newspaper_name]:\n",
    "                    faces_rawcount_per_decade[newspaper_name][decade] = num_faces #if not there, add the number as the first one\n",
    "                else:\n",
    "                    faces_rawcount_per_decade[newspaper_name][decade] += num_faces #if there, add the number to what is allready there\n",
    "\n",
    "\n",
    "\n",
    "        # now for calculating the percentage of pages with at least 1 face faces per decade:\n",
    "        # Calculate the total number of pages in the current newspaper\n",
    "        total_pages = len([filename for filename in os.listdir(full_path) if filename.endswith(\".jpg\")]) \n",
    "        \n",
    "        \n",
    "        #add % for each decase, should i loop? :\n",
    "\n",
    "        # Calculate the percentage\n",
    "        percentage = (sum(is_face_present) / total_pages) * 100 \n",
    "        perc_pages_with_faces_per_decade[newspaper_name][decade] = percentage\n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #save results to df\n",
    "    #for newspaper_name, data in faces_rawcount_per_decade.items():\n",
    "        #df = pd.DataFrame.from_dict(data, orient='index', columns=['Faces_Count'])\n",
    "        #df.to_csv(f'../out/{newspaper_name}_faces_per_decade.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save results into CSV files:\n",
    "#for newspaper_name, data in faces_rawcount_per_decade.items():\n",
    "    #df = pd.DataFrame.from_dict(data, orient='index', columns=['Faces_Count'])\n",
    "    #df.to_csv(f'../out/{newspaper_name}_faces_per_decade.csv')\n",
    "\n",
    "#for newspaper_name, data in perc_pages_with_faces_per_decade.items():\n",
    "    #df = pd.DataFrame.from_dict(data, orient='index', columns=['Percentage'])\n",
    "    #df.to_csv(f'..out/{newspaper_name}_percentage_per_decade.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test, still not what i want\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "# Initialize MTCNN for face detection:\n",
    "mtcnn = MTCNN()\n",
    "\n",
    "# Define folder path\n",
    "folderpath = \"../newspapers_2/\"\n",
    "\n",
    "# Initialize dictionaries to store results:\n",
    "faces_rawcount_per_decade = {}  # Store raw counts of images with faces per decade for each newspaper\n",
    "perc_pages_with_faces_per_decade = {}  # Store percentage of pages with faces per decade for each newspaper\n",
    "\n",
    "# Function to extract decade from filename:\n",
    "def extract_decade(filename):\n",
    "    parts = filename.split(\"-\")\n",
    "    year = int(parts[1])\n",
    "    decade = (year // 10) * 10\n",
    "    return decade\n",
    "\n",
    "# Iterate through each subfolder (newspaper) in folderpath:\n",
    "for newspaper_folder in os.listdir(folderpath):\n",
    "\n",
    "    # Construct the path to the newspaper we are looping through \n",
    "    full_path = os.path.join(folderpath, newspaper_folder)\n",
    "\n",
    "    # Check if the path full_path exist as a directory\n",
    "    if os.path.isdir(full_path):\n",
    "\n",
    "        # Extract the name of the newspaper from the folder path\n",
    "        newspaper_name = newspaper_folder.upper()\n",
    "\n",
    "        # Initialize dictionaries for the current newspaper\n",
    "        faces_rawcount_per_decade[newspaper_name] = {}\n",
    "        perc_pages_with_faces_per_decade[newspaper_name] = {}\n",
    "\n",
    "        # Initialize counter for pages with faces for the current decade\n",
    "        pages_with_faces = 0\n",
    "\n",
    "        # Initialize a list to track if faces are present on each page for the current decade\n",
    "        is_face_present = []\n",
    "\n",
    "        # Iterate through each file in the subfolder (newspaper):\n",
    "        for filename in os.listdir(full_path):\n",
    "\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(full_path, filename)\n",
    "\n",
    "            # Check if the current item is a file and ends with \".jpg\"\n",
    "            if os.path.isfile(file_path) and filename.endswith(\".jpg\"):\n",
    "\n",
    "                # Proceed with processing the image file\n",
    "                # Open the image file\n",
    "                img = Image.open(file_path)\n",
    "\n",
    "                # Extract the decade from the filename\n",
    "                decade = extract_decade(filename)\n",
    "\n",
    "                # Detect faces in the image:\n",
    "                boxes, _ = mtcnn.detect(img)\n",
    "\n",
    "                # Count faces per decade:\n",
    "                # Check if any face is detected\n",
    "                if boxes is not None:\n",
    "                    num_faces = boxes.shape[0]  # Count the number of detected faces\n",
    "                else:\n",
    "                    num_faces = 0  # No faces detected\n",
    "\n",
    "                # Increment the counter if at least one face is detected on this page\n",
    "                if num_faces > 0:\n",
    "                    pages_with_faces += 1\n",
    "                    is_face_present.append(True)  # Track if faces are present on this page\n",
    "                else:\n",
    "                    is_face_present.append(False)  # Track if faces are present on this page\n",
    "\n",
    "                # Update the count of faces for the current decade\n",
    "                if decade not in faces_rawcount_per_decade[newspaper_name]:\n",
    "                    faces_rawcount_per_decade[newspaper_name][decade] = num_faces\n",
    "                else:\n",
    "                    faces_rawcount_per_decade[newspaper_name][decade] += num_faces\n",
    "\n",
    "        # Calculate the total number of pages in the current newspaper\n",
    "        total_pages = len([filename for filename in os.listdir(full_path) if filename.endswith(\".jpg\")])\n",
    "\n",
    "        # Calculate the percentage of pages with at least one face for the current decade\n",
    "        if total_pages > 0:\n",
    "            percentage = (pages_with_faces / total_pages) * 100\n",
    "        else:\n",
    "            percentage = 0\n",
    "\n",
    "        # Store the percentage in the perc_pages_with_faces_per_decade dictionary\n",
    "        perc_pages_with_faces_per_decade[newspaper_name][decade] = percentage\n",
    "\n",
    "# Now you can use the results stored in faces_rawcount_per_decade and perc_pages_with_faces_per_decade dictionaries\n",
    "# for further analysis or visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IMP': {2010: 11, 1880: 0},\n",
       " 'JDG': {1990: 2, 1820: 0},\n",
       " 'GDL': {1990: 1, 1790: 0}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces_rawcount_per_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IMP': {1880: 37.5}, 'JDG': {1990: 25.0}, 'GDL': {1790: 12.5}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_pages_with_faces_per_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../newspapers_2/GDL/GDL-1798-02-05-a-p0001.jpg\n",
      "../newspapers_2/GDL/GDL-1798-02-05-a-p0002.jpg\n",
      "../newspapers_2/GDL/GDL-1798-02-05-a-p0003.jpg\n",
      "../newspapers_2/GDL/GDL-1798-02-05-a-p0004.jpg\n",
      "../newspapers_2/GDL/GDL-1997-08-09-a-p0029.jpg\n",
      "../newspapers_2/GDL/GDL-1997-08-09-a-p0030.jpg\n",
      "../newspapers_2/GDL/GDL-1997-08-09-a-p0031.jpg\n",
      "../newspapers_2/GDL/GDL-1997-08-09-a-p0032.jpg\n",
      "../newspapers_2/IMP/IMP-1882-05-04-a-p0001.jpg\n",
      "../newspapers_2/IMP/IMP-1882-05-04-a-p0002.jpg\n",
      "../newspapers_2/IMP/IMP-1882-05-04-a-p0003.jpg\n",
      "../newspapers_2/IMP/IMP-1882-05-04-a-p0004.jpg\n",
      "../newspapers_2/IMP/IMP-2017-12-30-a-p0025.jpg\n",
      "../newspapers_2/IMP/IMP-2017-12-30-a-p0026.jpg\n",
      "../newspapers_2/IMP/IMP-2017-12-30-a-p0027.jpg\n",
      "../newspapers_2/IMP/IMP-2017-12-30-a-p0028.jpg\n",
      "../newspapers_2/JDG/JDG-1826-02-16-a-p0001.jpg\n",
      "../newspapers_2/JDG/JDG-1826-02-16-a-p0002.jpg\n",
      "../newspapers_2/JDG/JDG-1826-02-16-a-p0003.jpg\n",
      "../newspapers_2/JDG/JDG-1826-02-16-a-p0004.jpg\n",
      "../newspapers_2/JDG/JDG-1998-02-27-a-p0041.jpg\n",
      "../newspapers_2/JDG/JDG-1998-02-27-a-p0042.jpg\n",
      "../newspapers_2/JDG/JDG-1998-02-27-a-p0043.jpg\n",
      "../newspapers_2/JDG/JDG-1998-02-27-a-p0044.jpg\n"
     ]
    }
   ],
   "source": [
    "#test, getting all the deaces %\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "# Initialize MTCNN for face detection:\n",
    "mtcnn = MTCNN()\n",
    "\n",
    "# Define folder path\n",
    "folderpath = \"../newspapers_2/\"\n",
    "\n",
    "# Initialize dictionaries to store results:\n",
    "faces_rawcount_per_decade = {}  # Store raw counts of images with faces per decade for each newspaper\n",
    "perc_pages_with_faces_per_decade = {}  # Store percentage of pages with faces per decade for each newspaper\n",
    "\n",
    "# Function to extract decade from filename:\n",
    "def extract_decade(filename):\n",
    "    parts = filename.split(\"-\")\n",
    "    year = int(parts[1])\n",
    "    decade = (year // 10) * 10\n",
    "    return decade\n",
    "\n",
    "\n",
    "# Iterate through each subfolder (newspaper) in folderpath:\n",
    "for newspaper_folder in sorted(os.listdir(folderpath)):\n",
    "\n",
    "    # Construct the path to the newspaper we are looping through \n",
    "    full_path = os.path.join(folderpath, newspaper_folder)\n",
    "\n",
    "    # Check if the path full_path exist as a directory\n",
    "    if os.path.isdir(full_path):\n",
    "\n",
    "        # Extract the name of the newspaper from the folder path\n",
    "        newspaper_name = newspaper_folder.upper()\n",
    "\n",
    "        # Initialize dictionaries for the current newspaper\n",
    "        faces_rawcount_per_decade[newspaper_name] = {}\n",
    "        perc_pages_with_faces_per_decade[newspaper_name] = {}\n",
    "\n",
    "        # Initialize counter for pages with faces for the current decade\n",
    "        pages_with_faces = 0 #this is for every newpaper\n",
    "\n",
    "        # Initialize a list to track if faces are present on each page for the current decade\n",
    "        #is_face_present = []\n",
    "\n",
    "        # Iterate through each file in the subfolder (newspaper):\n",
    "        for filename in sorted(os.listdir(full_path)):\n",
    "\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(full_path, filename)\n",
    "            print(file_path)\n",
    "\n",
    "            # Check if the current item is a file and ends with \".jpg\"\n",
    "            if os.path.isfile(file_path) and filename.endswith(\".jpg\"):\n",
    "\n",
    "                # Proceed with processing the image file\n",
    "                # Open the image file\n",
    "                img = Image.open(file_path)\n",
    "\n",
    "                # Extract the decade from the filename\n",
    "                decade = extract_decade(filename)\n",
    "\n",
    "                # Detect faces in the image:\n",
    "                boxes, _ = mtcnn.detect(img)\n",
    "\n",
    "                # Count faces per decade:\n",
    "                # Check if any face is detected\n",
    "                if boxes is not None:\n",
    "                    num_faces = boxes.shape[0]  # Count the number of detected faces\n",
    "                else:\n",
    "                    num_faces = 0  # No faces detected\n",
    "\n",
    "                # Increment the counter if at least one face is detected on this page\n",
    "                if num_faces > 0:\n",
    "                    pages_with_faces += 1 #add to counter for that newspaper \n",
    "                    is_face_present = 1 # Track if faces are present on this page\n",
    "                else:\n",
    "                    is_face_present = 0  # Track if faces are present on this page\n",
    "\n",
    "                # Update the count of faces for the current decade\n",
    "                if decade not in faces_rawcount_per_decade[newspaper_name]:\n",
    "                    faces_rawcount_per_decade[newspaper_name][decade] = num_faces\n",
    "                else:\n",
    "                    faces_rawcount_per_decade[newspaper_name][decade] += num_faces\n",
    "\n",
    "                #can i Update the count of is_face_present  for the current decade\n",
    "                if decade not in perc_pages_with_faces_per_decade[newspaper_name]:\n",
    "                    perc_pages_with_faces_per_decade[newspaper_name][decade] = is_face_present\n",
    "                else:\n",
    "                    perc_pages_with_faces_per_decade[newspaper_name][decade] += is_face_present\n",
    "\n",
    "         \n",
    "\n",
    "        # Calculate the total number of pages in the current newspaper\n",
    "        #total_pages = len([filename for filename in os.listdir(full_path) if filename.endswith(\".jpg\")])\n",
    "\n",
    "        # Calculate the percentage of pages with at least one face for the current decade\n",
    "        #if total_pages > 0:\n",
    "            #percentage = (pages_with_faces / total_pages) * 100\n",
    "        #else:\n",
    "            #percentage = 0\n",
    "\n",
    "        # Store the percentage in the perc_pages_with_faces_per_decade dictionary\n",
    "        #perc_pages_with_faces_per_decade[newspaper_name][decade] = percentage\n",
    "\n",
    "# Now you can use the results stored in faces_rawcount_per_decade and perc_pages_with_faces_per_decade dictionaries\n",
    "# for further analysis or visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GDL': {1790: 0, 1990: 1},\n",
       " 'IMP': {1880: 0, 2010: 11},\n",
       " 'JDG': {1820: 0, 1990: 2}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces_rawcount_per_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GDL': {1790: 0, 1990: 1},\n",
       " 'IMP': {1880: 0, 2010: 3},\n",
       " 'JDG': {1820: 0, 1990: 2}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_pages_with_faces_per_decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_face_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 2:\n",
    "\n",
    "#loop through each subfolder in folderpath\n",
    "\n",
    "    #extract name of newspaper:\n",
    "    #newpaper_name = in subfolder the first charachters until '-' \n",
    "\n",
    "    #make an empty list to store decades:\n",
    "    #decades = []\n",
    "\n",
    "    #loop thoguh each file in subfolder:\n",
    "        #for file in subfolder:\n",
    "\n",
    "        # get decade:\n",
    "\n",
    "        ##make an empty list to store decades:\n",
    "        ##decades = []\n",
    "        \n",
    "        ##get filename:\n",
    "        ##filename = what comes after the last / in file\n",
    "\n",
    "        ##between the first '-' and second '-' in filename extract 3 first numbers:\n",
    "        ##3_numbers = \n",
    "\n",
    "\n",
    "        #add unique instances to decades list: \n",
    "        #if 3_numbers is not allready in decades, add it to the list\n",
    "            #else skip\n",
    "        \n",
    "        #for each decade in decades: \n",
    "            #take the filenames where 5-8th charachter matches the decase \n",
    "\n",
    "            #load in image:\n",
    "            #image_path= Image.open(path_to_image)\n",
    "\n",
    "\n",
    "\n",
    "            # make empty varibale for counting number of faces:\n",
    "            #faces_on_page_count= 0\n",
    "\n",
    "\n",
    "            #detect faces \n",
    "            #boxes, _ = mtcnn.detect(img)\n",
    "        \n",
    "\n",
    "            #if shape of boxes == Nonce\n",
    "                #add 0 to faces_on_page\n",
    "\n",
    "                #else\n",
    "                    #number_to_add = boxes.shape[0]\n",
    "                    #add number_to_add to faces_on_page_count\n",
    "            \n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "#x = decade, y= percentage, titel= name of newspaper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
